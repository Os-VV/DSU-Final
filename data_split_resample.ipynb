{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dac111ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate DSU-FIN\n",
    "import polars as pl\n",
    "import os\n",
    "import numpy as np\n",
    "import gc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "if not os.getcwd() == 'e:\\\\python_projects\\\\notebooks\\\\Deep learning\\\\FIN':\n",
    "    os.chdir('e:\\\\python_projects\\\\notebooks\\\\Deep learning\\\\FIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f5f90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_root = os.getcwd() + '\\\\OD-TINA\\\\data\\\\'\n",
    "files = []\n",
    "\n",
    "for (a, d, f) in os.walk(data_root):\n",
    "    files.extend(os.path.join(a, n) for n in f)\n",
    "\n",
    "schema = pl.scan_parquet(files[0]).collect_schema()\n",
    "cat_cols = []\n",
    "feature_columns = []\n",
    "\n",
    "\n",
    "for k,v in schema.items():\n",
    "    if 'FEATURE' in k:\n",
    "        feature_columns.append(k)\n",
    "    if 'String' in str(v):\n",
    "        cat_cols.append(k)\n",
    "\n",
    "categories_pipeline = (\n",
    "    pl.scan_parquet(files).select(cat_cols)\n",
    "    )\n",
    "\n",
    "cat_cols_p = categories_pipeline.collect(streaming=True)\n",
    "cat_val_dict = {}\n",
    "for colname in cat_cols:\n",
    "    cat_val_dict[colname] = sorted(cat_cols_p[colname].unique().to_list())\n",
    "\n",
    "num_columns = [col for col in feature_columns if col not in cat_cols]\n",
    "\n",
    "dfs = []\n",
    "cat_dfs = []\n",
    "sample_period = '15s'\n",
    "\n",
    "for f in files:\n",
    "    ldf = (pl.scan_parquet(f)\n",
    "           .cast({pl.Float64: pl.Float32})\n",
    "           .with_columns(pl.from_epoch(pl.col('unix'), time_unit='s'))\n",
    "           .with_columns(\n",
    "           *[\n",
    "            pl.col(col).cast(pl.Enum(categories=cats))\n",
    "            for col, cats in cat_val_dict.items()\n",
    "            ]\n",
    "            )\n",
    "            .select([pl.col('unix'), pl.all().exclude('unix')])\n",
    "            .sort('unix')\n",
    "            .rename({'unix': 'Timestamp'})\n",
    "            )\n",
    "    ldf_cat = ldf.select(['Timestamp'] + cat_cols)\n",
    "\n",
    "    ldf = ldf.group_by_dynamic(\n",
    "        index_column = 'Timestamp',\n",
    "        every=sample_period,).agg(pl.col(num_columns).mean().name.prefix(\"mean_\"),\n",
    "                          )\n",
    "    df = ldf.collect(streaming = True)\n",
    "    cat_df =ldf_cat.collect(streaming = True)\n",
    "    cat_dfs.append(cat_df)\n",
    "    dfs.append(df)\n",
    "    \n",
    "\n",
    "tina_resampled = pl.concat(dfs)\n",
    "tina_resampled.write_parquet('tina_numeric_resampled.parquet')\n",
    "del tina_resampled, dfs\n",
    "gc.collect()\n",
    "\n",
    "tina_categorical = pl.concat(cat_dfs)\n",
    "tina_categorical = tina_categorical.to_dummies(tina_categorical.columns[1:])\n",
    "\n",
    "tina_categorical = tina_categorical.group_by_dynamic(\n",
    "                                    index_column = 'Timestamp',\n",
    "                                    every=sample_period,).agg(pl.col(tina_categorical.columns[1:]).max()\n",
    "                                    )\n",
    "tina_categorical.write_parquet('tina_categorical_resampled.parquet')\n",
    "del tina_categorical, cat_dfs\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67850d94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tina_full_num_lazy = pl.scan_parquet('tina_numeric_resampled.parquet').cast({pl.Float64: pl.Float32})\n",
    "tina_full_cat_lazy = pl.scan_parquet('tina_categorical_resampled.parquet').cast({pl.Float64: pl.Float32})\n",
    "data_size = tina_full_num_lazy.select(pl.len()).collect().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb163b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(data_size * .6)\n",
    "val_size = int(data_size * .2)\n",
    "test_size = data_size - train_size - val_size\n",
    "\n",
    "tina_train = tina_full_num_lazy.slice(0, train_size).fill_null(strategy = 'backward').collect().write_parquet('tina_train_15s.parquet')\n",
    "tina_val = tina_full_num_lazy.slice(train_size, val_size).fill_null(strategy = 'backward').collect().write_parquet('tina_val_15s.parquet')\n",
    "tina_test = tina_full_num_lazy.slice(train_size + val_size).fill_null(strategy = 'backward').collect().write_parquet('tina_test_15s.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

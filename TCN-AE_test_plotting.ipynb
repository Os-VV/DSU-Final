{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "410bf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda activate DSU-FIN\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from TCN_AE_model_3 import CustomDataset, encoder_decoder_tcn\n",
    "import holoviews as hv\n",
    "# from holoviews.operation.datashader import rasterize\n",
    "import panel as pn\n",
    "import joblib\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "if not os.getcwd() == 'e:\\\\python_projects\\\\notebooks\\\\Deep learning\\\\FIN':\n",
    "    os.chdir('e:\\\\python_projects\\\\notebooks\\\\Deep learning\\\\FIN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9d6d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55d506aa0299433dbe18c817c335b3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/88 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 1\n",
    "\n",
    "hour = 4 * 60\n",
    "win_size_hours = 24\n",
    "win_size = win_size_hours * hour\n",
    "\n",
    "test_dataset = CustomDataset('tina_test_15s.parquet', win_size = win_size, stride = win_size, train = False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "model_test = encoder_decoder_tcn()\n",
    "model_test = model_test\n",
    "rescaler = joblib.load('tina_train_scaler_fit.joblib')\n",
    "model_test.load_state_dict(torch.load(r'model states\\TCN-AE_15s_SL1_m3.pth', weights_only=True))\n",
    "y_reconstructed = []\n",
    "model_test.eval()\n",
    "with torch.no_grad():\n",
    "    for x_batch, y_batch in tqdm(test_loader):\n",
    "        x_batch = x_batch\n",
    "        y_batch = y_batch\n",
    "        output = model_test(x_batch)\n",
    "        output = output.squeeze(dim=0).cpu().numpy()\n",
    "        output = rescaler.inverse_transform(output)\n",
    "        mini_frame = pl.DataFrame(output)\n",
    "        y_reconstructed.append(mini_frame)\n",
    "\n",
    "reconstructed_df = pl.concat(y_reconstructed)\n",
    "reconstructed_df.write_parquet(f'tina_TCN_reconstructed_test.parquet')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "330365a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "maintenance = (pl.scan_parquet('tina_categorical_resampled.parquet')\n",
    "               .select(['Timestamp', 'm_id_none'])\n",
    "               .with_columns(pl.col('m_id_none').alias('maintenance_active')\n",
    "                            .replace_strict([0,1],[1,0])\n",
    "                            # .cast(pl.Boolean)\n",
    "                            )\n",
    "                .drop('m_id_none')\n",
    "               ).collect()\n",
    "\n",
    "reconstructed_df = pl.read_parquet('tina_TCN_reconstructed_test.parquet')\n",
    "original_df = pl.read_parquet('tina_test_15s.parquet')\n",
    "original_df = original_df.select(list(original_df.schema)[:104])\n",
    "reconstructed_df.columns = original_df.drop('Timestamp').columns\n",
    "\n",
    "original_df_adjusted = original_df.head(len(reconstructed_df))\n",
    "reconstructed_df.insert_column(0, original_df_adjusted['Timestamp'])\n",
    "original_df_adjusted = original_df_adjusted.join(maintenance, on=\"Timestamp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345df6c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = {'mean_FEATURE0': np.float32(0.42150515),\n",
    " 'mean_FEATURE1': np.float32(0.20319732),\n",
    " 'mean_FEATURE2': np.float32(0.19615193),\n",
    " 'mean_FEATURE3': np.float32(0.022218227),\n",
    " 'mean_FEATURE4': np.float32(1.6782992),\n",
    " 'mean_FEATURE5': np.float32(0.9842625),\n",
    " 'mean_FEATURE6': np.float32(1.238128),\n",
    " 'mean_FEATURE7': np.float32(0.3900614),\n",
    " 'mean_FEATURE8': np.float32(0.8386512),\n",
    " 'mean_FEATURE9': np.float32(4.7902703),\n",
    " 'mean_FEATURE10': np.float32(25.071886),\n",
    " 'mean_FEATURE11': np.float32(0.68052346),\n",
    " 'mean_FEATURE12': np.float32(0.580897),\n",
    " 'mean_FEATURE13': np.float32(1.0724338),\n",
    " 'mean_FEATURE14': np.float32(3.0758564),\n",
    " 'mean_FEATURE15': np.float32(2.3383162),\n",
    " 'mean_FEATURE16': np.float32(1.0236775),\n",
    " 'mean_FEATURE17': np.float32(0.77520007),\n",
    " 'mean_FEATURE18': np.float32(0.44730085),\n",
    " 'mean_FEATURE19': np.float32(3.2971532),\n",
    " 'mean_FEATURE20': np.float32(12.365843),\n",
    " 'mean_FEATURE21': np.float32(0.6211181),\n",
    " 'mean_FEATURE22': np.float32(1.1344229),\n",
    " 'mean_FEATURE23': np.float32(0.8430721),\n",
    " 'mean_FEATURE24': np.float32(0.63013124),\n",
    " 'mean_FEATURE25': np.float32(3.816558),\n",
    " 'mean_FEATURE26': np.float32(2.782583),\n",
    " 'mean_FEATURE27': np.float32(0.47515142),\n",
    " 'mean_FEATURE28': np.float32(1.0020258),\n",
    " 'mean_FEATURE29': np.float32(0.6994351),\n",
    " 'mean_FEATURE30': np.float32(1.3310556),\n",
    " 'mean_FEATURE31': np.float32(1.3016282),\n",
    " 'mean_FEATURE32': np.float32(0.6494755),\n",
    " 'mean_FEATURE33': np.float32(1.7902198),\n",
    " 'mean_FEATURE34': np.float32(0.84186566),\n",
    " 'mean_FEATURE35': np.float32(1.1881871),\n",
    " 'mean_FEATURE36': np.float32(0.8173567),\n",
    " 'mean_FEATURE37': np.float32(0.9609527),\n",
    " 'mean_FEATURE38': np.float32(0.70542216),\n",
    " 'mean_FEATURE39': np.float32(0.9593457),\n",
    " 'mean_FEATURE40': np.float32(0.24280973),\n",
    " 'mean_FEATURE41': np.float32(6.729699),\n",
    " 'mean_FEATURE42': np.float32(65.7806),\n",
    " 'mean_FEATURE43': np.float32(29.497036),\n",
    " 'mean_FEATURE44': np.float32(73.27882),\n",
    " 'mean_FEATURE45': np.float32(72.04436),\n",
    " 'mean_FEATURE46': np.float32(0.12973951),\n",
    " 'mean_FEATURE47': np.float32(39.81871),\n",
    " 'mean_FEATURE48': np.float32(0.6874012),\n",
    " 'mean_FEATURE49': np.float32(2.631487),\n",
    " 'mean_FEATURE50': np.float32(8.569691),\n",
    " 'mean_FEATURE51': np.float32(16.772371),\n",
    " 'mean_FEATURE52': np.float32(4.852936),\n",
    " 'mean_FEATURE53': np.float32(4.394761),\n",
    " 'mean_FEATURE54': np.float32(1.4145783),\n",
    " 'mean_FEATURE55': np.float32(1.4421047),\n",
    " 'mean_FEATURE56': np.float32(1.7880461),\n",
    " 'mean_FEATURE57': np.float32(1.4248106),\n",
    " 'mean_FEATURE58': np.float32(1.2754639),\n",
    " 'mean_FEATURE59': np.float32(0.5794825),\n",
    " 'mean_FEATURE60': np.float32(0.6251785),\n",
    " 'mean_FEATURE61': np.float32(0.46940377),\n",
    " 'mean_FEATURE62': np.float32(6.2848806),\n",
    " 'mean_FEATURE63': np.float32(10.612053),\n",
    " 'mean_FEATURE64': np.float32(0.38072827),\n",
    " 'mean_FEATURE65': np.float32(0.48745218),\n",
    " 'mean_FEATURE66': np.float32(1.2376535),\n",
    " 'mean_FEATURE67': np.float32(1.0539542),\n",
    " 'mean_FEATURE68': np.float32(6.6541386),\n",
    " 'mean_FEATURE69': np.float32(6.602502),\n",
    " 'mean_FEATURE70': np.float32(0.064529434),\n",
    " 'mean_FEATURE71': np.float32(3.0184615),\n",
    " 'mean_FEATURE72': np.float32(5.8108697),\n",
    " 'mean_FEATURE73': np.float32(1.5436399),\n",
    " 'mean_FEATURE74': np.float32(1.5069355),\n",
    " 'mean_FEATURE75': np.float32(1.4054474),\n",
    " 'mean_FEATURE77': np.float32(13.545437),\n",
    " 'mean_FEATURE78': np.float32(3.8061817),\n",
    " 'mean_FEATURE79': np.float32(4.2149167),\n",
    " 'mean_FEATURE80': np.float32(0.7022148),\n",
    " 'mean_FEATURE81': np.float32(4.649055),\n",
    " 'mean_FEATURE82': np.float32(3.7959857),\n",
    " 'mean_FEATURE83': np.float32(0.64080125),\n",
    " 'mean_FEATURE84': np.float32(0.34190345),\n",
    " 'mean_FEATURE85': np.float32(5.2414594),\n",
    " 'mean_FEATURE86': np.float32(9.276079),\n",
    " 'mean_FEATURE88': np.float32(1.0083756),\n",
    " 'mean_FEATURE89': np.float32(1.7892221),\n",
    " 'mean_FEATURE90': np.float32(1.2886363),\n",
    " 'mean_FEATURE91': np.float32(6.958557),\n",
    " 'mean_FEATURE92': np.float32(6.505038),\n",
    " 'mean_FEATURE93': np.float32(12.650433),\n",
    " 'mean_FEATURE94': np.float32(1.8494279),\n",
    " 'mean_FEATURE95': np.float32(2.8939722),\n",
    " 'mean_FEATURE96': np.float32(2.5196197),\n",
    " 'mean_FEATURE97': np.float32(4.460838),\n",
    " 'mean_FEATURE98': np.float32(3.183247),\n",
    " 'mean_FEATURE99': np.float32(6.1216874),\n",
    " 'mean_FEATURE100': np.float32(7.7625403),\n",
    " 'mean_FEATURE101': np.float32(26.114592),\n",
    " 'mean_FEATURE102': np.float32(2.2858553),\n",
    " 'mean_FEATURE103': np.float32(8.826485),\n",
    " 'mean_FEATURE104': np.float32(1.4738482)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5191d4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error(true_df, reconstructed_df, feature, threshholds, save_path=False):\n",
    "    hv.extension('bokeh')\n",
    "    feature = feature\n",
    "    thresh = threshholds[feature].item()\n",
    "    orig = f'original {feature}'\n",
    "    reconst = f'reconstructed {feature}'\n",
    "\n",
    "    new_df = pl.DataFrame({'Timestamp': true_df['Timestamp'], \n",
    "                            orig: true_df[feature], \n",
    "                            reconst: reconstructed_df[feature],\n",
    "                            'maintenance_active': true_df['maintenance_active']                            \n",
    "                            })\n",
    "    \n",
    "    new_df = new_df.with_columns(\n",
    "         error=(pl.col(orig) - pl.col(reconst)).pow(2))\n",
    "    new_df = new_df.with_columns(\n",
    "        anomaly = (pl.col('error') >= thresh)\n",
    "    )\n",
    "    \n",
    "    curve_true = hv.Curve((new_df['Timestamp'], new_df[orig]), \n",
    "                          label = orig).opts(color='green', alpha = 0.5)\n",
    "    curve_reconstructed = hv.Curve((new_df['Timestamp'], new_df[reconst]), \n",
    "                                   label = reconst).opts(color='red', alpha = 0.5)\n",
    "    curve_error = hv.Curve((new_df['Timestamp'], new_df['error']), \n",
    "                           label = f'Reconstruction squared error').opts(color='purple', alpha = 0.2)\n",
    "\n",
    "    anomaly_timestamps = new_df.filter(pl.col('anomaly')).select('Timestamp')\n",
    "    anomaly_lines = hv.VLines(anomaly_timestamps['Timestamp'].to_list(), label = 'anomaly').opts(\n",
    "        color='purple',\n",
    "        line_width=1.5,\n",
    "        alpha = 0.3\n",
    "        )\n",
    "    \n",
    "    max_error = new_df['error'].max()\n",
    "    new_df = new_df.with_columns(\n",
    "    scaled_maintenance_active=pl.when(pl.col('maintenance_active') == 1)\n",
    "                                .then(max_error)\n",
    "                                .otherwise(0)\n",
    "    )\n",
    "    maint = hv.Area(\n",
    "    (new_df['Timestamp'], new_df['scaled_maintenance_active']), \n",
    "                    label='maintenance_active').opts(\n",
    "    color='grey', alpha=0.2)\n",
    "    maint_neg = hv.Area(\n",
    "    (new_df['Timestamp'], -new_df['scaled_maintenance_active']), \n",
    "                    label='maintenance_active').opts(\n",
    "    color='grey', alpha=0.2)\n",
    "\n",
    "    overlay = (curve_true * curve_reconstructed * anomaly_lines * maint * maint_neg * curve_error).opts(width=1600, height=600, show_grid=True)\n",
    "\n",
    "    if save_path:\n",
    "        save_path = f'reconst errors\\\\{feature}_anomaly_TEST'\n",
    "        hv.save(overlay, save_path, fmt='html')\n",
    "        hv.save(overlay, save_path, fmt='png')\n",
    "        print(f'File saved at {save_path}')\n",
    "    # overlay\n",
    "    else:\n",
    "        return overlay #combined_dashboard\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70446a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'mean_FEATURE11'\n",
    "plot_error(original_df_adjusted, reconstructed_df, feature, thresholds, save_path=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33c3096",
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in list(reconstructed_df.schema)[1:]:\n",
    "    plot_error(original_df_adjusted, reconstructed_df, feature, thresholds, save_path=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
